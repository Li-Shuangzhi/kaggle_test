{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple\n",
      "Collecting scikit-learn\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/52/2d/ad6928a578c78bb0e44e34a5a922818b14c56716b81d145924f1f291416f/scikit_learn-1.3.2-cp38-cp38-win_amd64.whl (9.3 MB)\n",
      "     ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 0.8/9.3 MB 16.8 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 2.0/9.3 MB 26.0 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 3.6/9.3 MB 28.7 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 4.3/9.3 MB 21.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 7.0/9.3 MB 29.9 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 7.0/9.3 MB 29.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 8.6/9.3 MB 26.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 9.3/9.3 MB 24.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\lsz\\.conda\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\lsz\\.conda\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "     ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 302.2/302.2 kB ? eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/b1/2c/f504e55d98418f2fcf756a56877e6d9a45dd5ed28b3d7c267b300e85ad5b/threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.2 threadpoolctl-3.3.0\n",
      "Looking in indexes: https://pypi.mirrors.ustc.edu.cn/simple\n",
      "Collecting albumentations\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/95/78/046ba720532436716050c27fd71cb838d14a2dc4b676b7a0883e1e3deebe/albumentations-1.4.1-py3-none-any.whl (130 kB)\n",
      "     ---------------------------------------- 0.0/130.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 130.5/130.5 kB 3.9 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.24.4 (from albumentations)\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/69/65/0d47953afa0ad569d12de5f65d964321c208492064c38fe3b0b9744f8d44/numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "     ---------------------------------------- 0.0/14.9 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 1.5/14.9 MB 32.2 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 3.2/14.9 MB 33.7 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 4.0/14.9 MB 37.0 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 4.7/14.9 MB 25.2 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 6.3/14.9 MB 26.9 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 7.3/14.9 MB 26.0 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 8.9/14.9 MB 27.3 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 10.8/14.9 MB 28.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 12.5/14.9 MB 29.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 14.3/14.9 MB 36.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 14.9/14.9 MB 32.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\lsz\\.conda\\envs\\pytorch_env\\lib\\site-packages (from albumentations) (1.10.1)\n",
      "Collecting scikit-image>=0.21.0 (from albumentations)\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/d7/d1/a4c715ad640c9eb0daaa77c4ce561b06e086bec44cbc79083e3548b00b76/scikit_image-0.21.0-cp38-cp38-win_amd64.whl (22.7 MB)\n",
      "     ---------------------------------------- 0.0/22.7 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 1.8/22.7 MB 38.8 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 3.5/22.7 MB 36.9 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 3.5/22.7 MB 36.9 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 6.3/22.7 MB 33.7 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 8.1/22.7 MB 34.3 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 9.9/22.7 MB 35.0 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 9.9/22.7 MB 35.2 MB/s eta 0:00:01\n",
      "     ------------------- ------------------- 11.4/22.7 MB 29.8 MB/s eta 0:00:01\n",
      "     ---------------------- ---------------- 12.9/22.7 MB 29.8 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 14.5/22.7 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 15.9/22.7 MB 29.7 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 17.4/22.7 MB 28.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 19.0/22.7 MB 29.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 20.7/22.7 MB 32.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  22.7/22.7 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 22.7/22.7 MB 32.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML in c:\\users\\lsz\\.conda\\envs\\pytorch_env\\lib\\site-packages (from albumentations) (6.0.1)\n",
      "Collecting typing-extensions>=4.9.0 (from albumentations)\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/f9/de/dc04a3ea60b22624b51c703a84bbe0184abcd1d0b9bc8074b5d6b7ab90bb/typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.3.2 in c:\\users\\lsz\\.conda\\envs\\pytorch_env\\lib\\site-packages (from albumentations) (1.3.2)\n",
      "Collecting opencv-python-headless>=4.9.0 (from albumentations)\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/20/44/458a0a135866f5e08266566b32ad9a182a7a059a894effe6c41a9c841ff1/opencv_python_headless-4.9.0.80-cp37-abi3-win_amd64.whl (38.5 MB)\n",
      "     ---------------------------------------- 0.0/38.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 1.8/38.5 MB 38.3 MB/s eta 0:00:01\n",
      "     --- ------------------------------------ 3.6/38.5 MB 37.9 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 5.2/38.5 MB 36.6 MB/s eta 0:00:01\n",
      "     ------- -------------------------------- 6.9/38.5 MB 36.4 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 8.4/38.5 MB 35.9 MB/s eta 0:00:01\n",
      "     ---------- ---------------------------- 10.1/38.5 MB 35.8 MB/s eta 0:00:01\n",
      "     ----------- --------------------------- 11.6/38.5 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------- ------------------------- 13.4/38.5 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------- ----------------------- 15.3/38.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------- ---------------------- 16.3/38.5 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------ -------------------- 17.8/38.5 MB 32.7 MB/s eta 0:00:01\n",
      "     ------------------- ------------------- 19.0/38.5 MB 34.4 MB/s eta 0:00:01\n",
      "     ------------------- ------------------- 19.0/38.5 MB 34.4 MB/s eta 0:00:01\n",
      "     -------------------- ------------------ 20.2/38.5 MB 28.4 MB/s eta 0:00:01\n",
      "     ----------------------- --------------- 23.6/38.5 MB 31.2 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 24.5/38.5 MB 27.3 MB/s eta 0:00:01\n",
      "     ------------------------- ------------- 25.4/38.5 MB 27.3 MB/s eta 0:00:01\n",
      "     ------------------------- ------------- 25.4/38.5 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 26.7/38.5 MB 22.6 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 29.0/38.5 MB 23.4 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 29.6/38.5 MB 27.3 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 29.6/38.5 MB 27.3 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 32.3/38.5 MB 22.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 33.8/38.5 MB 22.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 35.3/38.5 MB 24.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 35.7/38.5 MB 32.8 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 35.7/38.5 MB 32.8 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.5/38.5 MB 27.3 MB/s eta 0:00:01\n",
      "     --------------------------------------- 38.5/38.5 MB 24.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\lsz\\.conda\\envs\\pytorch_env\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\lsz\\.conda\\envs\\pytorch_env\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (10.0.1)\n",
      "Collecting imageio>=2.27 (from scikit-image>=0.21.0->albumentations)\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/02/25/66533a8390e3763cf8254dee143dbf8a830391ea60d2762512ba7f9ddfbe/imageio-2.34.0-py3-none-any.whl (313 kB)\n",
      "     ---------------------------------------- 0.0/313.4 kB ? eta -:--:--\n",
      "     ------------------------------------- 313.4/313.4 kB 20.2 MB/s eta 0:00:00\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image>=0.21.0->albumentations)\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/06/a3/68d17088a4f09565bc7341fd20490da8191ec4cddde479daaabbe07bb603/tifffile-2023.7.10-py3-none-any.whl (220 kB)\n",
      "     ---------------------------------------- 0.0/220.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 220.9/220.9 kB ? eta 0:00:00\n",
      "Collecting PyWavelets>=1.1.1 (from scikit-image>=0.21.0->albumentations)\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/a9/8f/f80ff31e73385b886c35fb9fb1377849f9c43a3c1195ed8dc8ed8dc1bd88/PyWavelets-1.4.1-cp38-cp38-win_amd64.whl (4.2 MB)\n",
      "     ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "     ------------- -------------------------- 1.5/4.2 MB 30.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 2.9/4.2 MB 30.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  4.2/4.2 MB 29.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.2/4.2 MB 29.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\lsz\\.conda\\envs\\pytorch_env\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (23.1)\n",
      "Collecting lazy_loader>=0.2 (from scikit-image>=0.21.0->albumentations)\n",
      "  Downloading https://mirrors.bfsu.edu.cn/pypi/web/packages/a1/c3/65b3814e155836acacf720e5be3b5757130346670ac454fee29d3eda1381/lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lsz\\.conda\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn>=1.3.2->albumentations) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lsz\\.conda\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn>=1.3.2->albumentations) (3.3.0)\n",
      "Installing collected packages: typing-extensions, numpy, lazy_loader, tifffile, PyWavelets, opencv-python-headless, imageio, scikit-image, albumentations\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "Successfully installed PyWavelets-1.4.1 albumentations-1.4.1 imageio-2.34.0 lazy_loader-0.3 numpy-1.24.3 opencv-python-headless-4.9.0.80 scikit-image-0.21.0 tifffile-2023.7.10 typing-extensions-4.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\lsz\\.conda\\envs\\pytorch_env\\Lib\\site-packages\\numpy\\~libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\lsz\\AppData\\Local\\Temp\\pip-uninstall-cve10lno'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\lsz\\.conda\\envs\\pytorch_env\\Lib\\site-packages\\numpy\\~-t'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\lsz\\.conda\\envs\\pytorch_env\\Lib\\site-packages\\numpy\\~-nalg'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\lsz\\.conda\\envs\\pytorch_env\\Lib\\site-packages\\numpy\\~-ndom'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "d2l 0.17.5 requires numpy==1.21.5, but you have numpy 1.24.4 which is incompatible.\n",
      "jupyterlab-server 2.25.2 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-11T14:22:48.741231Z",
     "iopub.status.busy": "2023-09-11T14:22:48.740163Z",
     "iopub.status.idle": "2023-09-11T14:22:48.748777Z",
     "shell.execute_reply": "2023-09-11T14:22:48.747828Z",
     "shell.execute_reply.started": "2023-09-11T14:22:48.741191Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlr_scheduler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CosineAnnealingWarmRestarts,ExponentialLR\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets \n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts,ExponentialLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T14:19:53.446713Z",
     "iopub.status.busy": "2023-09-11T14:19:53.445834Z",
     "iopub.status.idle": "2023-09-11T14:19:53.530223Z",
     "shell.execute_reply": "2023-09-11T14:19:53.529265Z",
     "shell.execute_reply.started": "2023-09-11T14:19:53.446665Z"
    }
   },
   "outputs": [],
   "source": [
    "#标签和类别数进行对应\n",
    "train = pd.read_csv(\"/kaggle/input/classify-leaves/train.csv\")\n",
    "labels = list(pd.read_csv(\"/kaggle/input/classify-leaves/train.csv\")['label'])\n",
    "labels_unique = list(set(list(labels))) #list index--labels\n",
    "label_nums = []\n",
    "for i in range(len(labels)):\n",
    "    label_nums.append(labels_unique.index(labels[i]))\n",
    "train['number'] = label_nums\n",
    "# train.to_csv(\"./train_num_label.csv\", index = 0) #记录对应关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T14:13:14.880603Z",
     "iopub.status.busy": "2023-09-11T14:13:14.879816Z",
     "iopub.status.idle": "2023-09-11T14:13:14.898599Z",
     "shell.execute_reply": "2023-09-11T14:13:14.897706Z",
     "shell.execute_reply.started": "2023-09-11T14:13:14.880563Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/kaggle/input/classify-leaves/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T14:13:15.298373Z",
     "iopub.status.busy": "2023-09-11T14:13:15.297521Z",
     "iopub.status.idle": "2023-09-11T14:13:15.323147Z",
     "shell.execute_reply": "2023-09-11T14:13:15.322159Z",
     "shell.execute_reply.started": "2023-09-11T14:13:15.298342Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data,eval_data = train_test_split(train,test_size=0.2,stratify=train['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T14:20:21.900133Z",
     "iopub.status.busy": "2023-09-11T14:20:21.89977Z",
     "iopub.status.idle": "2023-09-11T14:20:21.910127Z",
     "shell.execute_reply": "2023-09-11T14:20:21.909012Z",
     "shell.execute_reply.started": "2023-09-11T14:20:21.900103Z"
    }
   },
   "outputs": [],
   "source": [
    "class Leaf_Dataset(Dataset):\n",
    "    '''\n",
    "    树叶数据集的训练集 自定义Dataset\n",
    "    '''\n",
    "    def __init__(self, train_csv, transform = None, test = False):\n",
    "        '''\n",
    "        train_path : 传入记录图像路径及其标号的csv文件\n",
    "        transform : 对图像进行的变换\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.train_csv = train_csv\n",
    "        self.image_path = list(self.train_csv['image']) #图像所在地址记录\n",
    "        self.test = test\n",
    "        if not self.test:\n",
    "            self.label_nums = list(self.train_csv['number']) #图像的标号记录\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        idx : 所需要获取的图像的索引\n",
    "        return : image， label\n",
    "        '''\n",
    "        image = cv2.imread(os.path.join(\"/kaggle/input/classify-leaves\", self.image_path[idx]))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         image = Image.open(os.path.join(\"/kaggle/input/classify-leaves\", self.image_path[idx]))\n",
    "        if(self.transform != None):\n",
    "            image = self.transform(image = image)['image']\n",
    "        if not self.test:\n",
    "            label = self.label_nums[idx]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T14:20:23.092777Z",
     "iopub.status.busy": "2023-09-11T14:20:23.09188Z",
     "iopub.status.idle": "2023-09-11T14:20:23.098147Z",
     "shell.execute_reply": "2023-09-11T14:20:23.096934Z",
     "shell.execute_reply.started": "2023-09-11T14:20:23.092735Z"
    }
   },
   "outputs": [],
   "source": [
    "# #data agumentation\n",
    "# transforms_train = torchvision.transforms.Compose([\n",
    "#     transforms.Resize((320, 320)),\n",
    "#     transforms.RandomHorizontalFlip(p=0.5),\n",
    "#     transforms.RandomVerticalFlip(p=0.5),\n",
    "#     transforms.ColorJitter(brightness=0.2,contrast=0.2, saturation=0.2, hue=0),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "# ])\n",
    "# transforms_test = torchvision.transforms.Compose([\n",
    "#     transforms.Resize((320, 320)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T14:20:23.484742Z",
     "iopub.status.busy": "2023-09-11T14:20:23.483858Z",
     "iopub.status.idle": "2023-09-11T14:20:23.493513Z",
     "shell.execute_reply": "2023-09-11T14:20:23.492042Z",
     "shell.execute_reply.started": "2023-09-11T14:20:23.484702Z"
    }
   },
   "outputs": [],
   "source": [
    "transforms_train = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(320, 320),\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.VerticalFlip(p=0.5),\n",
    "        albumentations.Rotate(limit=180, p=0.7),\n",
    "        albumentations.RandomBrightnessContrast(),\n",
    "        albumentations.ShiftScaleRotate(\n",
    "            shift_limit=0.25, scale_limit=0.1, rotate_limit=0\n",
    "        ),\n",
    "        albumentations.Normalize(\n",
    "            [0.485, 0.456, 0.406], [0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0, always_apply=True\n",
    "        ),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ]\n",
    ")\n",
    "transforms_test = albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(320, 320),\n",
    "            albumentations.Normalize(\n",
    "                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0, always_apply=True\n",
    "            ),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T14:21:54.100365Z",
     "iopub.status.busy": "2023-09-11T14:21:54.099961Z",
     "iopub.status.idle": "2023-09-11T14:21:54.117497Z",
     "shell.execute_reply": "2023-09-11T14:21:54.116582Z",
     "shell.execute_reply.started": "2023-09-11T14:21:54.100338Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(train_loader, valid_loader, device = torch.device(\"cuda:0\")):\n",
    "    net = torchvision.models.resnet50(weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "    in_features = net.fc.in_features\n",
    "    net.fc = nn.Linear(in_features, 176)\n",
    "    net = net.to(device)\n",
    "    epoch = 30\n",
    "    best_epoch = 0\n",
    "    best_score = 0.0\n",
    "    best_model_state = None\n",
    "    early_stopping_round = 3\n",
    "    losses = []\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.0001,weight_decay=1e-5)\n",
    "    loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "#     scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min = 1e-6)\n",
    "    scheduler = ExponentialLR(optimizer, gamma=0.9,verbose=True)\n",
    "    for i in range(epoch):\n",
    "        acc = 0\n",
    "        loss_sum = 0\n",
    "        net.train()\n",
    "        for x, y in tqdm(train_loader):\n",
    "            x = torch.as_tensor(x, dtype=torch.float)\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(x)\n",
    "            loss_temp = loss(y_hat, y)\n",
    "            loss_sum += loss_temp\n",
    "            optimizer.zero_grad()\n",
    "            loss_temp.backward()\n",
    "            optimizer.step()\n",
    "#             scheduler.step()\n",
    "            acc += torch.sum(y_hat.argmax(dim=1).type(y.dtype) == y)\n",
    "        scheduler.step()\n",
    "        losses.append(loss_sum.cpu().detach().numpy() / len(train_loader))\n",
    "        print( \"epoch: \", i, \"loss=\", loss_sum.item(), \"训练集准确度=\",(acc/(len(train_loader)*train_loader.batch_size)).item(),end=\"\")\n",
    "\n",
    "        test_acc = 0\n",
    "        net.eval()\n",
    "        for x, y in tqdm(valid_loader):\n",
    "            x = x.to(device)\n",
    "            x = torch.as_tensor(x, dtype=torch.float)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(x)\n",
    "            test_acc += torch.sum(y_hat.argmax(dim=1).type(y.dtype) == y)\n",
    "        print(\"验证集准确度\", (test_acc / (len(valid_loader)*valid_loader.batch_size)).item())\n",
    "        if test_acc > best_score:\n",
    "            best_model_state = copy.deepcopy(net.state_dict())\n",
    "            best_score = test_acc\n",
    "            best_epoch = i\n",
    "            print('best epoch save!')\n",
    "        if i - best_epoch >= early_stopping_round:\n",
    "            break\n",
    "    net.load_state_dict(best_model_state)\n",
    "    testset = Leaf_Dataset(test, transform = transforms_test,test = True)\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, drop_last=False)\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for x in tqdm(test_loader):\n",
    "            x = x.to(device)\n",
    "            x = torch.as_tensor(x, dtype=torch.float)\n",
    "            y_hat = net(x)\n",
    "            predict = torch.argmax(y_hat,dim=1).reshape(-1)\n",
    "            predict = list(predict.cpu().detach().numpy())\n",
    "            predictions.extend(predict)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data,eval_data = train_test_split(train,test_size=0.2,stratify=train['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T14:23:15.138039Z",
     "iopub.status.busy": "2023-09-11T14:23:15.137146Z",
     "iopub.status.idle": "2023-09-11T16:32:00.102732Z",
     "shell.execute_reply": "2023-09-11T16:32:00.101016Z",
     "shell.execute_reply.started": "2023-09-11T14:23:15.137992Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=2023)\n",
    "prediction_df = pd.DataFrame()\n",
    "for fold_n, (trn_idx, val_idx) in enumerate(skf.split(train, train['number'])):\n",
    "    print(f'fold {fold_n} training...')\n",
    "    train_data = train.iloc[trn_idx]\n",
    "    eval_data = train.iloc[val_idx]\n",
    "    trainset = Leaf_Dataset(train_data, transform = transforms_train)\n",
    "    evalset = Leaf_Dataset(eval_data, transform = transforms_test)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, drop_last=False)\n",
    "    eval_loader = torch.utils.data.DataLoader(evalset, batch_size=32, shuffle=False, drop_last=False)\n",
    "    predictions = train_model(train_loader, eval_loader)\n",
    "    prediction_df[f'fold_{fold_n}'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T16:32:05.34578Z",
     "iopub.status.busy": "2023-09-11T16:32:05.345033Z",
     "iopub.status.idle": "2023-09-11T16:32:07.409613Z",
     "shell.execute_reply": "2023-09-11T16:32:07.408649Z",
     "shell.execute_reply.started": "2023-09-11T16:32:05.345747Z"
    }
   },
   "outputs": [],
   "source": [
    "all_predictions = list(prediction_df.mode(axis=1)[0].astype(int))\n",
    "predict_label = []\n",
    "for i in range(len(all_predictions)):\n",
    "    predict_label.append(labels_unique[all_predictions[i]])\n",
    "\n",
    "submission = pd.read_csv(\"/kaggle/input/classify-leaves/test.csv\")\n",
    "submission[\"label\"] = pd.Series(predict_label)\n",
    "submission.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T16:32:12.810666Z",
     "iopub.status.busy": "2023-09-11T16:32:12.810307Z",
     "iopub.status.idle": "2023-09-11T16:32:12.827318Z",
     "shell.execute_reply": "2023-09-11T16:32:12.826375Z",
     "shell.execute_reply.started": "2023-09-11T16:32:12.810637Z"
    }
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T08:33:22.633182Z",
     "iopub.status.busy": "2023-09-11T08:33:22.632847Z",
     "iopub.status.idle": "2023-09-11T09:38:10.632024Z",
     "shell.execute_reply": "2023-09-11T09:38:10.630799Z",
     "shell.execute_reply.started": "2023-09-11T08:33:22.633153Z"
    }
   },
   "outputs": [],
   "source": [
    "# trainset = Leaf_Dataset(train_data, transform = transforms_train)\n",
    "# evalset = Leaf_Dataset(eval_data, transform = transforms_test)\n",
    "# # testset = Leaf_Test_Dataset(\"\", transform = transforms_test)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, drop_last=False)\n",
    "# eval_loader = torch.utils.data.DataLoader(evalset, batch_size=32, shuffle=False, drop_last=False)\n",
    "# # test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, drop_last=False)\n",
    "# net = train(train_loader, eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-10T15:47:39.244358Z",
     "iopub.status.busy": "2023-09-10T15:47:39.243962Z",
     "iopub.status.idle": "2023-09-10T15:47:39.250966Z",
     "shell.execute_reply": "2023-09-10T15:47:39.24991Z",
     "shell.execute_reply.started": "2023-09-10T15:47:39.244326Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T09:38:18.731413Z",
     "iopub.status.busy": "2023-09-11T09:38:18.73033Z",
     "iopub.status.idle": "2023-09-11T09:41:33.618818Z",
     "shell.execute_reply": "2023-09-11T09:41:33.617875Z",
     "shell.execute_reply.started": "2023-09-11T09:38:18.731381Z"
    }
   },
   "outputs": [],
   "source": [
    "# # TTA eval\n",
    "# device = torch.device(\"cuda:0\")\n",
    "# testset = Leaf_Dataset(eval_data, transform = transforms_train)\n",
    "# test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, drop_last=False)\n",
    "# all_predictions = []\n",
    "# for i in range(5):\n",
    "#     predictions = []\n",
    "#     with torch.no_grad():\n",
    "#         for x,_ in tqdm(test_loader):\n",
    "#             x = x.to(device)\n",
    "#             x = torch.as_tensor(x, dtype=torch.float)\n",
    "#             y_hat = net(x)\n",
    "#             predict = torch.argmax(y_hat,dim=1).reshape(-1)\n",
    "#             predict = list(predict.cpu().detach().numpy())\n",
    "#             predictions.extend(predict)\n",
    "#     all_predictions.append(predictions)\n",
    "# all_predictions = list(pd.DataFrame(all_predictions).T.mode(axis=1)[0].astype(int))\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# accuracy_score(all_predictions,eval_data['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T09:41:33.621363Z",
     "iopub.status.busy": "2023-09-11T09:41:33.620824Z",
     "iopub.status.idle": "2023-09-11T09:43:47.711122Z",
     "shell.execute_reply": "2023-09-11T09:43:47.710241Z",
     "shell.execute_reply.started": "2023-09-11T09:41:33.621327Z"
    }
   },
   "outputs": [],
   "source": [
    "# testset = Leaf_Dataset(test, transform = transforms_test,test = True)\n",
    "# test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, drop_last=False)\n",
    "# device = torch.device(\"cuda:0\")\n",
    "# predictions = []\n",
    "# with torch.no_grad():\n",
    "#     for x in tqdm(test_loader):\n",
    "#         x = x.to(device)\n",
    "#         x = torch.as_tensor(x, dtype=torch.float)\n",
    "#         y_hat = net(x)\n",
    "#         predict = torch.argmax(y_hat,dim=1).reshape(-1)\n",
    "#         predict = list(predict.cpu().detach().numpy())\n",
    "#         predictions.extend(predict)\n",
    "\n",
    "# predict_label = []\n",
    "# for i in range(len(predictions)):\n",
    "#     predict_label.append(labels_unique[predictions[i]])\n",
    "\n",
    "# submission = pd.read_csv(\"/kaggle/input/classify-leaves/test.csv\")\n",
    "# submission[\"label\"] = pd.Series(predict_label)\n",
    "# submission.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-11T09:43:47.713004Z",
     "iopub.status.busy": "2023-09-11T09:43:47.712638Z",
     "iopub.status.idle": "2023-09-11T09:51:43.161389Z",
     "shell.execute_reply": "2023-09-11T09:51:43.160423Z",
     "shell.execute_reply.started": "2023-09-11T09:43:47.712957Z"
    }
   },
   "outputs": [],
   "source": [
    "# # TTA test\n",
    "# device = torch.device(\"cuda:0\")\n",
    "# testset = Leaf_Dataset(test, transform = transforms_train, test=True)\n",
    "# test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, drop_last=False)\n",
    "# all_predictions = []\n",
    "# for i in range(5):\n",
    "#     predictions = []\n",
    "#     with torch.no_grad():\n",
    "#         for x in tqdm(test_loader):\n",
    "#             x = x.to(device)\n",
    "#             x = torch.as_tensor(x, dtype=torch.float)\n",
    "#             y_hat = net(x)\n",
    "#             predict = torch.argmax(y_hat,dim=1).reshape(-1)\n",
    "#             predict = list(predict.cpu().detach().numpy())\n",
    "#             predictions.extend(predict)\n",
    "#     all_predictions.append(predictions)\n",
    "# all_predictions = list(pd.DataFrame(all_predictions).T.mode(axis=1)[0].astype(int))\n",
    "# predict_label = []\n",
    "# for i in range(len(all_predictions)):\n",
    "#     predict_label.append(labels_unique[all_predictions[i]])\n",
    "\n",
    "# submission = pd.read_csv(\"/kaggle/input/classify-leaves/test.csv\")\n",
    "# submission[\"label\"] = pd.Series(predict_label)\n",
    "# submission.to_csv(\"result2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 2318453,
     "sourceId": 29193,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30497,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
